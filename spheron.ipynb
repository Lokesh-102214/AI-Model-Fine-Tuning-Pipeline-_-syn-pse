{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021ecd25-481c-402b-8969-5cd67e42c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.4.1+cu121)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (4.6.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.11/site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (3.0.1)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (2.9.2)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from gradio-client==1.8.0->gradio) (2024.9.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.2.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (5.27.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.11/site-packages (from optuna) (1.13.3)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.11/site-packages (from optuna) (2.0.35)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (4.3.6)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.24.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m167.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading peft-0.15.1-py3-none-any.whl (411 kB)\n",
      "Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m138.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.19.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m212.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading absl_py-2.2.1-py3-none-any.whl (277 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading aiohttp-3.11.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m195.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m184.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading sentry_sdk-2.24.1-py2.py3-none-any.whl (336 kB)\n",
      "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m169.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m181.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Downloading multidict-6.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: sentencepiece, pydub, xxhash, werkzeug, websockets, uvicorn, tomlkit, tensorboardX, tensorboard-data-server, shellingham, setproctitle, sentry-sdk, semantic-version, safetensors, ruff, regex, python-multipart, propcache, orjson, multidict, mdurl, markdown, grpcio, groovy, frozenlist, ffmpy, docker-pycreds, dill, colorlog, aiohappyeyeballs, aiofiles, absl-py, yarl, tensorboard, starlette, multiprocess, markdown-it-py, huggingface-hub, aiosignal, wandb, tokenizers, safehttpx, rich, optuna, gradio-client, fastapi, aiohttp, typer, transformers, bitsandbytes, accelerate, peft, gradio, datasets, evaluate\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed absl-py-2.2.1 accelerate-1.5.2 aiofiles-23.2.1 aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 bitsandbytes-0.45.4 colorlog-6.9.0 datasets-3.5.0 dill-0.3.8 docker-pycreds-0.4.0 evaluate-0.4.3 fastapi-0.115.12 ffmpy-0.5.0 frozenlist-1.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 grpcio-1.71.0 huggingface-hub-0.29.3 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.2.0 multiprocess-0.70.16 optuna-4.2.1 orjson-3.10.16 peft-0.15.1 propcache-0.3.1 pydub-0.25.1 python-multipart-0.0.20 regex-2024.11.6 rich-13.9.4 ruff-0.11.2 safehttpx-0.1.6 safetensors-0.5.3 semantic-version-2.10.0 sentencepiece-0.2.0 sentry-sdk-2.24.1 setproctitle-1.3.5 shellingham-1.5.4 starlette-0.46.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 tokenizers-0.21.1 tomlkit-0.13.2 transformers-4.50.3 typer-0.15.2 uvicorn-0.34.0 wandb-0.19.8 websockets-15.0.1 werkzeug-3.1.3 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate sentencepiece gradio tensorboard tensorboardX optuna datasets peft bitsandbytes wandb torch transformers evaluate rouge_score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7c56d8-f60d-4387-915e-7ffdf1f3c31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140d45106bb74b4f9902ce022e87dd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c4e53a-5710-428b-b102-29b9758f5ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d08590b81542bbbd410b17153da7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('Llama 3', 'Mistral', 'SmolLM'), style=DescriptionStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define available models\n",
    "model_options = [\"Llama 3\", \"Mistral\", \"SmolLM\"]\n",
    "\n",
    "# Create a dropdown widget\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=model_options,\n",
    "    description=\"Model:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1eceb7-bfd1-4a5a-922e-4657b75d676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SmolLM (TinyLlama/TinyLlama-1.1B-Chat-v1.0)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:862: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ea9ca435be471fb1104207960ef023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940af1ed13f64c59b041836bfc11fc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f51a9745e44ab091955403ded6cbb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e60b0388ec48558afa1b177beb945f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d47ceb3b774b70b7c89e6243e12c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35f81478a694f809676df4c7260476d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626bed6971ae44418047d72113e96f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmolLM loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Function to load the selected model\n",
    "def load_model(model_name):\n",
    "    model_map = {\n",
    "        \"Llama 3\": \"meta-llama/Llama-3.1-8B\",\n",
    "        \"Mistral\": \"mistralai/Mistral-7B-v0.1\",\n",
    "        \"SmolLM\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "    }\n",
    "\n",
    "    if model_name in model_map:\n",
    "        model_id = model_map[model_name]\n",
    "        print(f\"Loading {model_name} ({model_id})...\")\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", use_auth_token=True)\n",
    "\n",
    "        print(f\"{model_name} loaded successfully!\")\n",
    "        return model, tokenizer\n",
    "    else:\n",
    "        print(\"Invalid model selection.\")\n",
    "        return None, None\n",
    "\n",
    "# Load the model based on user selection\n",
    "selected_model = model_dropdown.value\n",
    "model, tokenizer = load_model(selected_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48f3cf8-2172-45b6-b998-bc9f91a60a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102b3759ac684d6cb765cfa935806f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.json,.csv,.jsonl', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create file uploader widget\n",
    "file_uploader = widgets.FileUpload(accept=\".json,.csv,.jsonl\", multiple=False)\n",
    "display(file_uploader)\n",
    "\n",
    "# Function to read and validate dataset\n",
    "def process_dataset(uploaded_files):\n",
    "    if not uploaded_files:\n",
    "        print(\"❌ No file uploaded.\")\n",
    "        return None\n",
    "\n",
    "    # Extract the first uploaded file from tuple\n",
    "    uploaded_file = uploaded_files[0]  # Fix: Extract from tuple\n",
    "\n",
    "    # Access name and content\n",
    "    file_name = uploaded_file.name\n",
    "    content = uploaded_file.content  # Extract file content as bytes\n",
    "\n",
    "    # Convert content to BytesIO for pandas\n",
    "    file_stream = io.BytesIO(content)\n",
    "\n",
    "    # Read file based on format\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        df = pd.read_csv(file_stream)\n",
    "    elif file_name.endswith(\".json\"):\n",
    "        df = pd.read_json(file_stream)\n",
    "    elif file_name.endswith(\".jsonl\"):\n",
    "        content_str = content.decode(\"utf-8\").split(\"\\n\")\n",
    "        data = [json.loads(line) for line in content_str if line.strip()]\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        print(\"❌ Unsupported file format.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"✅ Dataset Loaded: {file_name}\")\n",
    "    print(df.head())  # Show first few rows\n",
    "    return df\n",
    "\n",
    "# Function to handle file upload event\n",
    "def on_upload(change):\n",
    "    global dataset\n",
    "    dataset = process_dataset(file_uploader.value)  # Process dataset\n",
    "\n",
    "# Attach the event listener\n",
    "file_uploader.observe(on_upload, names=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50330a4f-d508-403f-9b3b-1d1660d27319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset prepared successfully!\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 324\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 40\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 41\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_hf_dataset(df, text_column=\"text\", extract_key=None, max_length=512):\n",
    "    global tokenizer  \n",
    "\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"❌ Column '{text_column}' not found in dataset!\")\n",
    "\n",
    "    # Extract the key from the dictionary if needed\n",
    "    if extract_key:\n",
    "        df[text_column] = df[text_column].apply(lambda x: x.get(extract_key, []) if isinstance(x, dict) else [])\n",
    "\n",
    "    # Flatten the list of patterns into individual rows\n",
    "    df = df.explode(text_column)\n",
    "\n",
    "    # Split into train, validation, and test (80-10-10)\n",
    "    train_texts, temp_texts = train_test_split(df[text_column].dropna().tolist(), test_size=0.2, random_state=42)\n",
    "    val_texts, test_texts = train_test_split(temp_texts, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Tokenization\n",
    "    tokenized_dataset = DatasetDict({\n",
    "        \"train\": Dataset.from_dict(tokenizer(train_texts, truncation=True, padding=\"max_length\", max_length=max_length)),\n",
    "        \"validation\": Dataset.from_dict(tokenizer(val_texts, truncation=True, padding=\"max_length\", max_length=max_length)),\n",
    "        \"test\": Dataset.from_dict(tokenizer(test_texts, truncation=True, padding=\"max_length\", max_length=max_length)),\n",
    "    })\n",
    "\n",
    "    print(\"✅ Dataset prepared successfully!\")\n",
    "    return tokenized_dataset\n",
    "    \n",
    "hf_dataset = prepare_hf_dataset(dataset, text_column=\"intents\", extract_key=\"patterns\")\n",
    "\n",
    "# Show dataset structure\n",
    "print(hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901987d9-510c-416f-81d8-5fb287ee4f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7fa046ab5e4b0f967831905a796cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3bec68a04c454c95793211f9cd911d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33840e8ce634fb5a11a0e9c55efc2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b007e56bf8ec480d91be0d564077ee84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatLogSlider(value=5e-05, description='Learning Rate', max=-3.0, min=-6.0, style=SliderStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf934504fbb4b84a0011c8b6090d447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=8, description='Batch Size', max=64, min=2, step=2, style=SliderStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa857cab422c48f98c03626b40a30349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=3, description='Epochs', max=10, min=1, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d759d8828e94d74882ca28935b74909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=4, description='Gradient Accumulation', max=16, min=1, style=SliderStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ea1e8ac6c4444a9ae670d1393ed10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatLogSlider(value=0.01, description='Weight Decay', max=0.0, min=-5.0, style=SliderStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c642703745e74b59942d194f6f9bfaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Start Training', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c2bb22a5e4427dab1c47773902181c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import time\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import DatasetDict\n",
    "import evaluate  # ✅ Replaces deprecated load_metric\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the dataset is correctly assigned\n",
    "hf_dataset = DatasetDict({\n",
    "    \"train\": hf_dataset[\"train\"],\n",
    "    \"validation\": hf_dataset[\"validation\"],\n",
    "    \"test\": hf_dataset[\"test\"]\n",
    "})\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # No masked language modeling\n",
    ")\n",
    "\n",
    "# Ensure dataset items are tensors\n",
    "def format_dataset(example):\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(example[\"input_ids\"], dtype=torch.long),\n",
    "        \"attention_mask\": torch.tensor(example[\"attention_mask\"], dtype=torch.long),\n",
    "        \"labels\": torch.tensor(example[\"input_ids\"], dtype=torch.long),\n",
    "    }\n",
    "\n",
    "hf_dataset = hf_dataset.map(format_dataset)\n",
    "\n",
    "# ✅ Replace deprecated load_metric with evaluate.load\n",
    "perplexity_metric = evaluate.load(\"perplexity\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Interactive UI for hyperparameter selection\n",
    "learning_rate_slider = widgets.FloatLogSlider(\n",
    "    value=5e-5, base=10, min=-6, max=-3, step=0.1,\n",
    "    description=\"Learning Rate\", style={'description_width': 'initial'}\n",
    ")\n",
    "batch_size_slider = widgets.IntSlider(\n",
    "    value=8, min=2, max=64, step=2,\n",
    "    description=\"Batch Size\", style={'description_width': 'initial'}\n",
    ")\n",
    "epochs_slider = widgets.IntSlider(\n",
    "    value=3, min=1, max=10, step=1,\n",
    "    description=\"Epochs\", style={'description_width': 'initial'}\n",
    ")\n",
    "gradient_accumulation_slider = widgets.IntSlider(\n",
    "    value=4, min=1, max=16, step=1,\n",
    "    description=\"Gradient Accumulation\", style={'description_width': 'initial'}\n",
    ")\n",
    "weight_decay_slider = widgets.FloatLogSlider(\n",
    "    value=0.01, base=10, min=-5, max=0, step=0.1,\n",
    "    description=\"Weight Decay\", style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(learning_rate_slider, batch_size_slider, epochs_slider, gradient_accumulation_slider, weight_decay_slider)\n",
    "\n",
    "# Function to define training arguments\n",
    "def get_training_args(\n",
    "    learning_rate=5e-5,\n",
    "    batch_size=8,\n",
    "    epochs=3,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0.01\n",
    "):\n",
    "    return TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"tensorboard\",\n",
    "        remove_unused_columns=False,\n",
    "        disable_tqdm=True  # ✅ Disable progress bars\n",
    "    )\n",
    "\n",
    "# Optuna hyperparameter tuning\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16, 32])\n",
    "    epochs = trial.suggest_int(\"epochs\", 2, 6)\n",
    "    grad_accum = trial.suggest_int(\"gradient_accumulation\", 1, 8)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-1)\n",
    "\n",
    "    training_args = get_training_args(learning_rate, batch_size, epochs, grad_accum, weight_decay)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=hf_dataset[\"train\"],\n",
    "        eval_dataset=hf_dataset[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    return eval_results[\"eval_loss\"]\n",
    "\n",
    "# Automatically run Optuna tuning if user does not modify defaults\n",
    "use_optuna = True  # Assume tuning unless user changes defaults\n",
    "default_values = {\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"batch_size\": 8,\n",
    "    \"epochs\": 3,\n",
    "    \"gradient_accumulation\": 4,\n",
    "    \"weight_decay\": 0.01\n",
    "}\n",
    "\n",
    "def check_user_changes():\n",
    "    global use_optuna\n",
    "    use_optuna = not (\n",
    "        learning_rate_slider.value != default_values[\"learning_rate\"] or\n",
    "        batch_size_slider.value != default_values[\"batch_size\"] or\n",
    "        epochs_slider.value != default_values[\"epochs\"] or\n",
    "        gradient_accumulation_slider.value != default_values[\"gradient_accumulation\"] or\n",
    "        weight_decay_slider.value != default_values[\"weight_decay\"]\n",
    "    )\n",
    "\n",
    "# Button to start training\n",
    "train_button = widgets.Button(description=\"Start Training\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_train_click(b):\n",
    "    global use_optuna\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        check_user_changes()\n",
    "\n",
    "        if use_optuna:\n",
    "            print(\"🔍 Running Hyperparameter Tuning with Optuna...\")\n",
    "            study = optuna.create_study(direction=\"minimize\")\n",
    "            study.optimize(objective, n_trials=10)\n",
    "            best_params = study.best_params\n",
    "            print(f\"🎯 Best Hyperparameters Found: {best_params}\")\n",
    "        else:\n",
    "            best_params = {\n",
    "                \"learning_rate\": learning_rate_slider.value,\n",
    "                \"batch_size\": batch_size_slider.value,\n",
    "                \"epochs\": epochs_slider.value,\n",
    "                \"gradient_accumulation_steps\": gradient_accumulation_slider.value,\n",
    "                \"weight_decay\": weight_decay_slider.value\n",
    "            }\n",
    "\n",
    "        print(\"🚀 Starting Training with Selected Parameters...\")\n",
    "        training_args = get_training_args(**best_params)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=hf_dataset[\"train\"],\n",
    "            eval_dataset=hf_dataset[\"validation\"],\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        print(\"✅ Training Completed!\")\n",
    "\n",
    "        print(\"📊 Evaluating Model...\")\n",
    "        eval_results = trainer.evaluate()\n",
    "        for key, value in eval_results.items():\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "        print(\"🎯 Training & Evaluation Complete!\")\n",
    "\n",
    "train_button.on_click(on_train_click)\n",
    "display(train_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bfe5697-f974-4640-b05d-1e7c68b5cfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (0.4.3)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.29.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.11/site-packages (from rouge_score) (2.2.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.11.14)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=61b4f53f30267cdcb105388aa3afd96f7b58d5f803d6980dc3c20051c4a689b6\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: nltk, rouge_score\n",
      "Successfully installed nltk-3.9.1 rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate rouge_score nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7e055-8126-4d5d-91f0-f349a23f7c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
